import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)
from keras.preprocessing.image import ImageDataGenerator, load_img
from tensorflow.keras.layers import Conv2D, Dense, BatchNormalization, Activation, Dropout, MaxPooling2D, Flatten,AveragePooling2D
from keras.optimizers import Adam, SGD
from tensorflow.keras import Sequential
import matplotlib.pyplot as plt
from keras.utils import plot_model
import cv2
import os
from tensorflow.keras.applications.vgg16 import VGG16
from tensorflow.keras.applications.resnet50 import ResNet50
from tensorflow.keras.callbacks import ModelCheckpoint,EarlyStopping
import warnings

warnings.filterwarnings("ignore")

train_dir = 'G:/Lab Assignment 3 Dataset/train/'
test_dir = 'G:/Lab Assignment 3 Dataset/test/'

print(train_dir)


##############OPTIONAL
def count_exp(path, set_):
    dict_ = {}
    for expression in os.listdir(path):
        dir_ = path + expression
        dict_[expression] = len(os.listdir(dir_))
    df = pd.DataFrame(dict_, index=[set_])
    return df
train_count = count_exp(train_dir, 'train')
test_count = count_exp(test_dir, 'test')
print(train_count)
print(test_count)

print('training pictures\n')
plt.figure(figsize=(14,22))
i = 1
for expression in os.listdir(train_dir):
    img = load_img((train_dir + expression +'/'+ os.listdir(train_dir + expression)[5]))
    plt.subplot(1,7,i)
    plt.imshow(img)
    plt.title(expression)
    plt.axis('off')
    i += 1
plt.show()

print('testing pictures\n')
plt.figure(figsize=(14,22))
i = 1
for expression in os.listdir(test_dir):
    img = load_img((test_dir + expression +'/'+ os.listdir(test_dir + expression)[5]))
    plt.subplot(1,7,i)
    plt.imshow(img)
    plt.title(expression)
    plt.axis('off')
    i += 1
plt.show()

##############

train_datagen = ImageDataGenerator(rescale=1./255,
                                   zoom_range=0.3,
                                   rotation_range=30,
                                   width_shift_range=0.2,
                                   height_shift_range=0.2,
                                   brightness_range=[0.4,1.5],
                                   horizontal_flip=True)

training_set = train_datagen.flow_from_directory(train_dir,
                                                batch_size=32,
                                                target_size=(224,224),
                                                shuffle=True,
                                                color_mode='rgb',
                                                class_mode='categorical')

test_datagen = ImageDataGenerator(rescale=1./255)
test_set = test_datagen.flow_from_directory(test_dir,
                                                batch_size=32,
                                                target_size=(224,224),
                                                shuffle=True,
                                                color_mode='rgb',
                                                class_mode='categorical')
vgg = VGG16(weights='imagenet',
              include_top=False,               
              input_shape = (224,224,3))
for layer in vgg.layers:
    layer.trainable = False
    
vgg16Model = Sequential()
vgg16Model.add(vgg)
vgg16Model.add(Flatten())
vgg16Model.add(Dense(2, activation = "softmax"))

vgg16Model.summary()


steps_per_epoch = training_set.n // training_set.batch_size
validation_steps = test_set.n // test_set.batch_size

checkpoint = ModelCheckpoint("vgg16.h5",monitor = "val_acc",save_best_only = True,verbose=1)
earlystop = EarlyStopping(monitor="val_acc",patience=8,verbose=1)

vgg16Model.compile(optimizer="adam",loss = "categorical_crossentropy",metrics = ["acc"])

hist = vgg16Model.fit(x=training_set,
                 validation_data=test_set,
                 epochs=10,
                 callbacks=[checkpoint,earlystop],
                 steps_per_epoch=steps_per_epoch,
                 validation_steps=validation_steps)
                 
                 
                 
plt.figure(figsize=(14,5))
plt.subplot(1,2,2)
plt.plot(hist.history['acc'])
plt.plot(hist.history['val_acc'])
plt.title('Model Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend(['train', 'test'], loc='upper left')
plt.subplot(1,2,1)
plt.plot(hist.history['loss'])
plt.plot(hist.history['val_loss'])
plt.title('model Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend(['train', 'test'], loc='upper left')
plt.show()
 
